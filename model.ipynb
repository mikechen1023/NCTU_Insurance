{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "pytorch == 1.5.0\n",
    "cuda == 10.1\n",
    "python == 3.8\n",
    "pandas == 0.25.0\n",
    "numpy == 1.18.4\n",
    "argparse == 1.1\n",
    "matplotlib == 3.1.1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 顯示全部的 column\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataAugumenting(data):\n",
    "    \"\"\"\n",
    "    Goal:\n",
    "        Data resample( duplicate \"the successful insurance policy\" )\n",
    "    \"\"\"\n",
    "    \n",
    "    # data augmentation\n",
    "    y_data = data[data['是否已受理']==1]\n",
    "    n_data = data[data['是否已受理']==0]\n",
    "\n",
    "    print('處理前:')\n",
    "    print('成交保單數 : ',len(y_data))\n",
    "    print('未成交保單數 : ',len(n_data))\n",
    "    print('保單總數 : ', len(data), end=\"\\n\\n\")\n",
    "    \n",
    "    times = len(n_data)//len(y_data)\n",
    "\n",
    "    new_y_data = y_data\n",
    "\n",
    "    for i in range(times-1):\n",
    "        new_y_data = pd.concat((new_y_data,y_data))\n",
    "\n",
    "    new_data = pd.concat((new_y_data, n_data))\n",
    "\n",
    "    print('處理後:')\n",
    "    print('成交保單數 : ',len(new_y_data))\n",
    "    print('未成交保單數 : ',len(n_data))\n",
    "    print('保單總數 : ', len(new_data), end=\"\\n\\n\")\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreprocessing(data, datatype, wealth_loyalty):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        param data : dataframe\n",
    "        param datatype : new/old customer\n",
    "        param wealth_loyalty : determine if put wealth and loyalty into datasets\n",
    "    \n",
    "    Output:\n",
    "        x : data (dtype: torch)\n",
    "        y : label (dtype: torch)\n",
    "    \"\"\"\n",
    "    \n",
    "    insurance = pd.DataFrame(data, columns=['保額', '保額區間', '保費', '保費區間', 'TWD'])\n",
    "    commodity = pd.DataFrame(data, columns=['商品分類_三標'])\n",
    "    age = pd.DataFrame(data, columns=['保險年齡'])\n",
    "    y = pd.DataFrame(data, columns=['是否已受理'])\n",
    "    \n",
    "    # commodity use embedding\n",
    "    type_dict = {'A&H':1, 'SP':2, 'RP1':3, 'RP2':4}\n",
    "    embeds = nn.Embedding(5, 4) # 5 means dict dim : 0-4\n",
    "    commodity = commodity.replace(type_dict)\n",
    "    commodity = torch.from_numpy(commodity.to_numpy())\n",
    "    commodity = torch.tensor(commodity, dtype=torch.long)\n",
    "    commodity_embedded = embeds(commodity)\n",
    "    commodity = commodity_embedded.view(commodity_embedded.size(0),4)\n",
    "\n",
    "\n",
    "#     # commodity use one-hot encoding\n",
    "#     commodity = pd.get_dummies(commodity)\n",
    "#     commodity = torch.from_numpy(commodity.to_numpy())\n",
    "    \n",
    "    # transfer other data to torch type\n",
    "    insurance = torch.from_numpy(insurance.to_numpy())\n",
    "    age = torch.from_numpy(age.to_numpy())\n",
    "    y = torch.from_numpy(y.to_numpy())\n",
    "    \n",
    "    \n",
    "    if datatype=='old':    #舊客戶\n",
    "        if wealth_loyalty:  # 使用客戶忠誠度、財富指標\n",
    "            level_dict = {'R1A':1, 'R1B':2, 'R1C':3, 'R2':4, 'R3':5, 'R4':6, 'R5':7}\n",
    "            customer = pd.DataFrame(data, columns=['客戶忠誠度', '財富指標'])\n",
    "            customer['客戶忠誠度'] = customer['客戶忠誠度'].str.get(1).astype(int)\n",
    "            customer['財富指標'] = customer['財富指標'].replace(level_dict)\n",
    "            customer = torch.from_numpy(customer.to_numpy())\n",
    "            x = torch.cat((insurance, age, customer, commodity), 1)\n",
    "        else:\n",
    "            customerLevel = pd.DataFrame(data, columns=['客戶分群(NEW)'])\n",
    "            customerLevel = customerLevel['客戶分群(NEW)'].str.get(1).astype(int)\n",
    "            customerLevel = torch.from_numpy(customerLevel.to_numpy())\n",
    "            customerLevel = customerLevel.view(customerLevel.size(0), 1)\n",
    "            x = torch.cat((insurance, age, customerLevel, commodity), 1)\n",
    "    else:    #新客戶\n",
    "        x = torch.cat((insurance, age, commodity), 1)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(csvpath, datatype, wealth_loyalty=False ,timesort=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        param csvpath : csv file path\n",
    "        param datatype : new/old customer\n",
    "        param wealth_loyalty : determine if put wealth and loyalty into datasets\n",
    "        param timesort : determine if sort the datetime when split data into train/test datasets\n",
    "        \n",
    "    Output:\n",
    "        x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    # get dataframe\n",
    "    df = pd.read_csv(csvpath, encoding=\"utf-8\", index_col=[0])\n",
    "    \n",
    "    if datatype == 'new' or datatype=='all':\n",
    "        data = pd.DataFrame(df, columns=['保額', '保額區間', '保費', '保費區間', '商品分類_三標', '保險年齡', 'TWD', '是否已受理', '建議書_建立日'])\n",
    "    else:    # old              \n",
    "        if wealth_loyalty:    # 使用忠誠度和財富指標\n",
    "            data = pd.DataFrame(df, columns=['保額', '保額區間', '保費', '保費區間', '商品分類_三標', '保險年齡', 'TWD', '是否已受理', '財富指標', '客戶忠誠度', '建議書_建立日']) \n",
    "        else:                 #使用客戶分群 \n",
    "            data = pd.DataFrame(df, columns=['保額', '保額區間', '保費', '保費區間', '商品分類_三標', '保險年齡', 'TWD', '是否已受理', '客戶分群(NEW)', '建議書_建立日']) #只用客戶分群\n",
    "\n",
    "    # Delete the row that has NaN\n",
    "    if datatype=='old':\n",
    "        data = data.dropna()\n",
    "    \n",
    "    # Data Augument\n",
    "    new_data = DataAugumenting(data)\n",
    "    \n",
    "    # sort datetime\n",
    "    if timesort:\n",
    "        # split data into train/test sets (split 8/2) with the sorting datetime\n",
    "        new_data = new_data.sort_values(by = '建議書_建立日').reset_index(drop=True)\n",
    "        train_data = new_data[0:int(len(new_data)*0.8)]\n",
    "        test_data = new_data[int(len(new_data)*0.8):]\n",
    "    else:\n",
    "        # split data into train/test sets (random with 8/2)\n",
    "        msk = np.random.rand(len(new_data)) < 0.8\n",
    "        train_data = new_data[msk]\n",
    "        test_data = new_data[~msk]\n",
    "    \n",
    "    # Data preprocessing\n",
    "    x_train, y_train = DataPreprocessing(train_data, datatype, wealth_loyalty)\n",
    "    x_test, y_test = DataPreprocessing(test_data, datatype, wealth_loyalty)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataloader(x, y, batch_size):\n",
    "    \"\"\"\n",
    "    Goal : change torch to dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    # change torch to dataset\n",
    "    dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "    dataloader = Data.DataLoader(\n",
    "        dataset = dataset,\n",
    "        batch_size = batch_size,\n",
    "        drop_last=True, \n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    acc = (rounded_preds == y).float()\n",
    "    acc = acc.sum() / len(y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class MyDNN(nn.Module):\n",
    "    def __init__(self, model_args):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.args = model_args\n",
    "        \n",
    "        # init args\n",
    "        self.input_dim = self.args.input_dim\n",
    "        self.hidden_dim = self.args.hidden_dim\n",
    "        self.output_dim = self.args.output_dim\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        output = self.layers(x.float())\n",
    "        return output\n",
    "    \n",
    "    def printModel(self):\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(object):\n",
    "    \"\"\"\n",
    "    Methods:\n",
    "        - fit()        : Train the model \n",
    "        - predict()    : Output the prediction\n",
    "        - evaluate()   : Calculate scores\n",
    "        - save_model() : Save the model (.h5)\n",
    "        \n",
    "    Parameters:\n",
    "        - epochs: int,\n",
    "            Numer of iterations to run all data\n",
    "            \n",
    "        - batch_size: int,\n",
    "            Minibatch size\n",
    "            \n",
    "        - learning rate: float,\n",
    "            Initial learning rate\n",
    "            \n",
    "        - use_cuda: boolean,\n",
    "            Run the model on gpu or cpu\n",
    "            \n",
    "        - optimizer: Algo of optimizer\n",
    "        \n",
    "        - criterion : Loss function\n",
    "        \n",
    "        - model_name: Model name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,\n",
    "                 epochs=None, \n",
    "                 batch_size=None, \n",
    "                 learning_rate=None,\n",
    "                 use_cuda=False, \n",
    "                 model_name=\"unknown_model.h5\", \n",
    "                 model_args=None):\n",
    "        \n",
    "        # model related\n",
    "        self._net = None\n",
    "        self.model_args = model_args\n",
    "        \n",
    "        # learning related\n",
    "        self._batch_size = batch_size\n",
    "        self._epochs = epochs\n",
    "        self._learning_rate = learning_rate\n",
    "        self._device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self._net = MyDNN(self.model_args).to(self._device)\n",
    "        self._optimizer = optim.SGD(self._net.parameters(), lr = self._learning_rate, momentum=0.9)\n",
    "        self._criterion = nn.BCELoss()\n",
    "        self._model_name = model_name\n",
    "            \n",
    "    def fit(self, trainloader):\n",
    "        self._net.train()\n",
    "        print(self._net)\n",
    "        \n",
    "        for epoch in range(self._epochs):\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for step, (batch_x, batch_y) in enumerate(trainLoader):\n",
    "            \n",
    "                batch_x = batch_x.to(self._device)\n",
    "                batch_y = batch_y.to(self._device)\n",
    "\n",
    "                preds = self._net(batch_x.long())\n",
    "                losses = self._criterion(preds, batch_y.float())\n",
    "                acc = binary_accuracy(preds, batch_y)\n",
    "                \n",
    "                # Back prop.\n",
    "                self._optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                self._optimizer.step()\n",
    "\n",
    "                epoch_loss += losses.item()\n",
    "                epoch_acc += acc\n",
    "            print('epoch:{} | loss:{:4f} | acc:{:4f}'.format(epoch+1, epoch_loss/len(trainLoader), epoch_acc/len(trainLoader)))\n",
    "            \n",
    "    def predict(self, x_test):\n",
    "        x_test = x_test.to(self._device)\n",
    "        return self._net(x_test)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        x_test = x_test.to(self._device)\n",
    "        \n",
    "        self._net.eval()\n",
    "        y_preds = self._net(x_test)\n",
    "        y_preds = y_preds.cpu()\n",
    "        y_preds = torch.round(y_preds)\n",
    "        \n",
    "        # 求 f1-score\n",
    "        TP=0; FN=0; FP=0; TN=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]-y_preds[i]==1:\n",
    "                FN += 1\n",
    "            elif y_test[i]-y_preds[i]==-1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                if y_test[i]==1: TP += 1\n",
    "                else: TN += 1\n",
    "\n",
    "        print([[TP, FN], [FP, TN]])\n",
    "\n",
    "        accuracy = (TP+TN)/len(y_test)\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f1_score = 2/((1/precision)+1/recall)\n",
    "\n",
    "        print('len:',len(y_test))\n",
    "        print('acc : ', accuracy)\n",
    "        print('recall: ', recall)\n",
    "        print('precision: ', precision)\n",
    "        print('f1 score : ', f1_score)\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self._net, './model/' + self._model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "        input_dim:\n",
    "            -新客戶: 10\n",
    "            -舊客戶: \n",
    "                - 使用客戶分群: 11\n",
    "                - 使用財富和忠誠度: 12\n",
    "    \"\"\"\n",
    "    \n",
    "    model_parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # model dependent arguments\n",
    "    model_parser = argparse.ArgumentParser()\n",
    "    model_parser.add_argument('--input_dim', type=int, default=10)\n",
    "    model_parser.add_argument('--hidden_dim', type=int, default=32)\n",
    "    model_parser.add_argument('--output_dim', type=int, default=1)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # data/train arguments\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001)\n",
    "    parser.add_argument('--use_cuda', type=bool, default=True)\n",
    "    \n",
    "    config = parser.parse_args(args=[])\n",
    "    model_config = model_parser.parse_args(args=[])\n",
    "    \n",
    "        \n",
    "    # data parameters\n",
    "    csvpath = \"./data/preprocessing_new.csv\"\n",
    "    datatype = 'new'\n",
    "    timesort = False\n",
    "    wealth_loyalty = False\n",
    "    \n",
    "    model_name = \"test.h5\"\n",
    "    \n",
    "    \n",
    "\n",
    "    # load data\n",
    "    x_train, y_train, x_test, y_test = getData(csvpath, datatype, wealth_loyalty, timesort)\n",
    "    trainLoader = getdataloader(x_train, y_train, config.batch_size)\n",
    "    \n",
    "    print('x_train: ',x_train.shape)\n",
    "    print('x_test: ',x_test.shape)\n",
    "    \n",
    "    model = Mymodel(epochs=config.epochs,\n",
    "                    batch_size=config.batch_size,\n",
    "                    learning_rate=config.learning_rate,\n",
    "                    use_cuda=config.use_cuda, \n",
    "                    model_name=model_name, \n",
    "                    model_args=model_config)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(trainLoader)\n",
    "    \n",
    "    # evaluate model\n",
    "    model.evaluate(x_test, y_test)\n",
    "    model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=12061; FN=12469; FP=12774; TN=18339\n",
    "accuracy = (TP+TN)/len(y_test)\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "f1_score = 2/((1/precision)+1/recall)\n",
    "\n",
    "print('len:',len(y_test))\n",
    "print('acc : ', accuracy)\n",
    "print('recall: ', recall)\n",
    "print('precision: ', precision)\n",
    "print('f1 score : ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(trainLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit(data, model, optimizer, criterion, batch_size, epochs, use_cuda=False):\n",
    "    \n",
    "#     # run model on a GPU or CPU\n",
    "#     device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "#     model._device = device\n",
    "    \n",
    "#     # set model to training mode\n",
    "#     model.train()\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "        \n",
    "#         epoch_loss = 0\n",
    "#         epoch_acc = 0\n",
    "        \n",
    "#         for step, (batch_x, batch_y) in enumerate(trainLoader):\n",
    "            \n",
    "#             batch_x = batch_x.to(device)\n",
    "#             batch_y = batch_y.to(device)\n",
    "\n",
    "#             preds = model(batch_x.long())\n",
    "#             losses = criterion(preds, batch_y.float())\n",
    "#             acc = binary_accuracy(preds, batch_y)\n",
    "\n",
    "#             optimizer.zero_grad()\n",
    "#             losses.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             epoch_loss += losses.item()\n",
    "#             epoch_acc += acc\n",
    "#         print('epoch:{} | loss:{:4f} | acc:{:4f}'.format(epoch+1, epoch_loss/len(trainLoader), epoch_acc/len(trainLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, x_test, y_test):\n",
    "    \n",
    "#     # set model to evaulating mode\n",
    "#     model.eval()\n",
    "    \n",
    "#     x_test = x_test.to(model._device)\n",
    "    \n",
    "#     # predict\n",
    "#     y_preds = model(x_test)\n",
    "#     y_preds = y_preds.cpu()\n",
    "#     y_preds = torch.round(y_preds)\n",
    "    \n",
    "#     # 求 f1-score\n",
    "#     TP=0; FN=0; FP=0; TN=0\n",
    "#     for i in range(len(y_test)):\n",
    "#         if y_test[i]-y_preds[i]==1:\n",
    "#             FN += 1\n",
    "#         elif y_test[i]-y_preds[i]==-1:\n",
    "#             FP += 1\n",
    "#         else:\n",
    "#             if y_test[i]==1: TP += 1\n",
    "#             else: TN += 1\n",
    "\n",
    "#     print([[TP, FN], [FP, TN]])\n",
    "\n",
    "#     accuracy = (TP+TN)/len(y_test)\n",
    "#     precision = TP/(TP+FP)\n",
    "#     recall = TP/(TP+FN)\n",
    "#     f1_score = 2/((1/precision)+1/recall)\n",
    "\n",
    "#     print('len:',len(y_test))\n",
    "#     print('acc : ',accuracy)\n",
    "#     print('recall: ',recall)\n",
    "#     print('f1 score : ',f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 建立 model\n",
    "# model = DNN(INPUT_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    "\n",
    "# # 設定 backprop.參數和 loss function\n",
    "# optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)\n",
    "# criterion = nn.BCELoss()\n",
    "\n",
    "# # 設定 GPU 運算\n",
    "# device = torch.device('cuda')\n",
    "\n",
    "# model = model.to(device)\n",
    "# criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # train\n",
    "# model.train()\n",
    "# for epoch in range(EPOCHS):\n",
    "    \n",
    "#     epoch_loss = 0\n",
    "#     epoch_acc = 0\n",
    "    \n",
    "#     for step, (batch_x, batch_y) in enumerate(trainLoader):\n",
    "        \n",
    "#         batch_x = batch_x.to(device)\n",
    "#         batch_y = batch_y.to(device)\n",
    "        \n",
    "#         preds = model.forward(batch_x.long())\n",
    "#         losses = criterion(preds, batch_y.float())\n",
    "#         acc = binary_accuracy(preds, batch_y)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         losses.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         epoch_loss += losses.item()\n",
    "#         epoch_acc += acc\n",
    "#     print('epoch:{} | loss:{:4f} | acc:{:4f}'.format(epoch+1, epoch_loss/len(trainLoader), epoch_acc/len(trainLoader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # evaulate\n",
    "# model.eval()\n",
    "# x_test = x_test.to(device)\n",
    "\n",
    "# y_preds = model(x_test)\n",
    "\n",
    "# y_preds = y_preds.cpu()\n",
    "# y_preds = torch.round(y_preds)\n",
    "\n",
    "# # 求 f1-score\n",
    "# TP=0; FN=0; FP=0; TN=0\n",
    "# for i in range(len(y_test)):\n",
    "#     if y_test[i]-y_preds[i]==1:\n",
    "#         FN += 1\n",
    "#     elif y_test[i]-y_preds[i]==-1:\n",
    "#         FP += 1\n",
    "#     else:\n",
    "#         if y_test[i]==1: TP += 1\n",
    "#         else: TN += 1\n",
    "\n",
    "# print([[TP, FN], [FP, TN]])\n",
    "\n",
    "# accuracy = (TP+TN)/len(y_test)\n",
    "# precision = TP/(TP+FP)\n",
    "# recall = TP/(TP+FN)\n",
    "# f1_score = 2/((1/precision)+1/recall)\n",
    "\n",
    "# print('len:',len(y_test))\n",
    "# print('acc : ',accuracy)\n",
    "# print('f1 score : ',f1_score)\n",
    "\n",
    "# cnt=0\n",
    "# for i in y_preds:\n",
    "#     if i.item()==1:\n",
    "#         cnt+=1\n",
    "\n",
    "# print('cnt: ',cnt)\n",
    "# print('total: ',len(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # load data\n",
    "\n",
    "# CSVPATH = \"./preprocessing_v3_new.csv\"\n",
    "# DATATYPE = 'new'\n",
    "# TIMESORT = True\n",
    "\n",
    "\n",
    "# x_train, y_train, x_test, y_test = getData(CSVPATH, DATATYPE, TIMESORT)\n",
    "\n",
    "# print('x_train: ', x_train.shape)\n",
    "# print('y_train: ', y_train.shape)\n",
    "# print('x_test: ', x_test.shape)\n",
    "# print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIM = 8\n",
    "# HIDDEN_DIM = 32\n",
    "# OUTPUT_DIM = 1\n",
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change torch to dataset\n",
    "# train_dataset = Data.TensorDataset(x_train, y_train)\n",
    "# test_dataset = Data.TensorDataset(x_test, y_test)\n",
    "\n",
    "# trainLoader = Data.DataLoader(\n",
    "#     dataset = train_dataset,\n",
    "#     batch_size = BATCH_SIZE,\n",
    "#     shuffle = True\n",
    "# )\n",
    "\n",
    "# testLoader = Data.DataLoader(\n",
    "#     dataset = test_dataset,\n",
    "#     shuffle = False\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     只用客戶分群\n",
    "# \"\"\"\n",
    "# def DataPreprocessing(data, datatype):\n",
    "    \n",
    "#     insurance = pd.DataFrame(data, columns=['保額', '保費', 'TWD'])\n",
    "#     commodity = pd.DataFrame(data, columns=['商品分類_三標'])\n",
    "#     age = pd.DataFrame(data, columns=['保險年齡'])\n",
    "#     y = pd.DataFrame(data, columns=['是否已受理'])\n",
    "    \n",
    "#     # set embedding dictionary\n",
    "#     type_dict = {'A&H(健康意外險)':0, 'SP(躉繳)':1, '躉繳':1, 'RP金流(壽險期繳金流型)':2, '終身壽險':2, 'RP保障(壽險期繳保障型)':3}\n",
    "#     embeds = nn.Embedding(4, 4)\n",
    "    \n",
    "#     commodity = commodity.replace(type_dict)\n",
    "#     commodity = torch.from_numpy(commodity.to_numpy())\n",
    "#     commodity = torch.tensor(commodity, dtype=torch.long)\n",
    "#     commodity_embedded = embeds(commodity)\n",
    "    \n",
    "#     # transfer other data to torch type\n",
    "#     insurance = torch.from_numpy(insurance.to_numpy())\n",
    "#     age = torch.from_numpy(age.to_numpy())\n",
    "#     y = torch.from_numpy(y.to_numpy())\n",
    "    \n",
    "#     commodity_embedded = commodity_embedded.view(commodity_embedded.size(0),4)\n",
    "    \n",
    "#     if datatype=='old':\n",
    "#         customerLevel = pd.DataFrame(data, columns=['客戶分群(NEW)'])\n",
    "#         customerLevel = customerLevel['客戶分群(NEW)'].str.get(1).astype(int)\n",
    "#         customerLevel = torch.from_numpy(customerLevel.to_numpy())\n",
    "#         customerLevel = customerLevel.view(customerLevel.size(0), 1)\n",
    "#         x = torch.cat((insurance, age, customerLevel, commodity_embedded), 1)\n",
    "#     else:\n",
    "#         x = torch.cat((insurance, age, commodity_embedded), 1)\n",
    "    \n",
    "#     return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test dataloader\n",
    "# for epoch in range(5):\n",
    "#     i=0\n",
    "#     for batch_x, batch_y in loader:\n",
    "#         i = i + 1\n",
    "#         print('Epoch:{} | num:{} | batch_x:{} | batch_y:{}'.format(epoch, i, batch_x, batch_y))\n",
    "\n",
    "# dataloader 使用\n",
    "# for epoch in range(1):\n",
    "#     i = 0\n",
    "#     for step, (batch_x, batch_y) in enumerate(loader):\n",
    "#         i += 1\n",
    "#         print('Epoch:{} | num:{} | batch_x:{} | batch_y:{}'.format(epoch, i, batch_x, batch_y), end=\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split data to train/test sets\n",
    "# msk = np.random.rand(len(new_data)) < 0.8\n",
    "# train_data = new_data[msk]\n",
    "# test_data = new_data[~msk]\n",
    "\n",
    "# print(len(new_data))\n",
    "# print(len(train_data))\n",
    "# print(len(test_data))\n",
    "\n",
    "# # get train data\n",
    "# insurance_train = pd.DataFrame(train_data, columns=['保額', '保費', 'TWD'])\n",
    "# commodity_train = pd.DataFrame(train_data, columns=['商品分類_三標'])\n",
    "# person_train = pd.DataFrame(train_data, columns=['保險年齡'])\n",
    "# y_train = pd.DataFrame(train_data, columns=['是否已受理'])\n",
    "\n",
    "\n",
    "# # get test data\n",
    "# insurance_test = pd.DataFrame(test_data, columns=['保額', '保費', 'TWD'])\n",
    "# commodity_test = pd.DataFrame(test_data, columns=['商品分類_三標'])\n",
    "# person_test = pd.DataFrame(test_data, columns=['保險年齡'])\n",
    "# y_test = pd.DataFrame(test_data, columns=['是否已受理'])\n",
    "\n",
    "\n",
    "# '''\n",
    "# embed the commodity data\n",
    "# '''\n",
    "\n",
    "# # set embedding dictionary\n",
    "# type_dict = {'A&H(健康意外險)':0, 'SP(躉繳)':1, '躉繳':1, 'RP金流(壽險期繳金流型)':2, '終身壽險':2, 'RP保障(壽險期繳保障型)':3}\n",
    "# embeds = nn.Embedding(4, 4)\n",
    "\n",
    "# # embedding\n",
    "# commodity_train = commodity_train.replace(type_dict)\n",
    "# commodity_train = torch.from_numpy(commodity_train.to_numpy())\n",
    "# commodity_test = commodity_test.replace(type_dict)\n",
    "# commodity_test = torch.from_numpy(commodity_test.to_numpy())\n",
    "\n",
    "# # transfer type from numpy to torch tensor (dtype = torch.long)\n",
    "# commodity_train = torch.tensor(commodity_train, dtype=torch.long)\n",
    "# commodity_train_embedded = embeds(commodity_train)\n",
    "# commodity_test = torch.tensor(commodity_test, dtype=torch.long)\n",
    "# commodity_test_embedded = embeds(commodity_test)\n",
    "\n",
    "# # transfer other data to torch type\n",
    "# insurance_train = torch.from_numpy(insurance_train.to_numpy())\n",
    "# person_train = torch.from_numpy(person_train.to_numpy())\n",
    "# y_train = torch.from_numpy(y_train.to_numpy())\n",
    "\n",
    "# insurance_test = torch.from_numpy(insurance_test.to_numpy())\n",
    "# person_test = torch.from_numpy(person_test.to_numpy())\n",
    "# y_test = torch.from_numpy(y_test.to_numpy())\n",
    "\n",
    "# # check data type\n",
    "# print('insurance_train: ', insurance_train.shape)\n",
    "# print('person_train', person_train.shape)\n",
    "# print('commodity_train_embedded', commodity_train_embedded.shape)\n",
    "\n",
    "# # concate the data\n",
    "# commodity_train_embedded = commodity_train_embedded.view(commodity_train_embedded.size(0),4)\n",
    "# x_train = torch.cat((insurance_train, person_train, commodity_train_embedded), 1)\n",
    "\n",
    "# commodity_test_embedded = commodity_test_embedded.view(commodity_test_embedded.size(0), 4)\n",
    "# x_test = torch.cat((insurance_test, person_test, commodity_test_embedded), 1)\n",
    "\n",
    "# # check data type\n",
    "# print(x_train.shape)\n",
    "# print(x_test.shape)\n",
    "# print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 測試 成交保單 的準確率\n",
    "\n",
    "# data_access = pd.DataFrame(df, columns=['保額', '保費', '商品分類_三標', '保險年齡', 'TWD', '是否已受理'])\n",
    "# data_access = data_access.dropna()\n",
    "\n",
    "# data_access['保額'] = data_access['保額'] * 100\n",
    "# data_access['保費'] = data_access['保費'] * 100\n",
    "\n",
    "# data_access = data_access[data_access['是否已受理'] == 0]\n",
    "\n",
    "# insurance_access = pd.DataFrame(data_access, columns=['保額', '保費', 'TWD'])\n",
    "# commodity_access = pd.DataFrame(data_access, columns=['商品分類_三標'])\n",
    "# person_access = pd.DataFrame(data_access, columns=['保險年齡'])\n",
    "# y_access = pd.DataFrame(data_access, columns=['是否已受理'])\n",
    "\n",
    "# type_dict = {'A&H(健康意外險)':0, 'SP(躉繳)':1, '躉繳':1, 'RP金流(壽險期繳金流型)':2, '終身壽險':2, 'RP保障(壽險期繳保障型)':3}\n",
    "# embeds = nn.Embedding(4, 4)\n",
    "\n",
    "# commodity_access = commodity_access.replace(type_dict)\n",
    "# commodity_access = torch.from_numpy(commodity_access.to_numpy())\n",
    "# commodity_access = torch.tensor(commodity_access, dtype=torch.long)\n",
    "# commodity_access_embedded = embeds(commodity_access)\n",
    "\n",
    "# insurance_access = torch.from_numpy(insurance_access.to_numpy())\n",
    "# person_access = torch.from_numpy(person_教師資格考試access.to_numpy())\n",
    "# y_access = torch.from_numpy(y_access.to_numpy())\n",
    "\n",
    "# commodity_access_embedded = commodity_access_embedded.view(commodity_access_embedded.size(0),4)\n",
    "# x_access = torch.cat((insurance_access, person_access, commodity_access_embedded), 1)\n",
    "\n",
    "# x_access = x_access.to(device)\n",
    "# y_access = y_access.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(x_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_accuracy(preds, y_access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in preds:\n",
    "    if i>0.5:\n",
    "        count+=1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count/len(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
