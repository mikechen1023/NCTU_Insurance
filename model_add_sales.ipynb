{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# 顯示全部的 column\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataAugumenting(data):\n",
    "    \"\"\"\n",
    "    Goal:\n",
    "        Data resample( duplicate \"the successful insurance policy\" )\n",
    "    \"\"\"\n",
    "    # data augmentation\n",
    "    y_data = data[data['是否已受理']==1]\n",
    "    n_data = data[data['是否已受理']==0]\n",
    "\n",
    "    print('處理前:')\n",
    "    print('成交保單數 : ',len(y_data))\n",
    "    print('未成交保單數 : ',len(n_data))\n",
    "    print('保單總數 : ', len(data), end=\"\\n\\n\")\n",
    "    \n",
    "    times = len(n_data)//len(y_data)\n",
    "\n",
    "    new_y_data = y_data\n",
    "\n",
    "    for i in range(times-1):\n",
    "        new_y_data = pd.concat((new_y_data,y_data))\n",
    "\n",
    "    new_data = pd.concat((new_y_data, n_data))\n",
    "\n",
    "    print('處理後:')\n",
    "    print('成交保單數 : ',len(new_y_data))\n",
    "    print('未成交保單數 : ',len(n_data))\n",
    "    print('保單總數 : ', len(new_data), end=\"\\n\\n\")\n",
    "    \n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreprocessing(data, datatype, wealth_loyalty):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        param data : dataframe\n",
    "        param datatype : new/old customer\n",
    "        param wealth_loyalty : determine if put wealth and loyalty into datasets\n",
    "    \n",
    "    Output:\n",
    "        x : data (dtype: torch)\n",
    "        y : label (dtype: torch)\n",
    "    \"\"\"\n",
    "    \n",
    "    sales = pd.DataFrame(data, columns=['R1A', 'R1B', 'R1C', 'R2', 'R3', 'R4', 'R5', 'L1', 'L2', 'L3', 'L4', 'L5', 'other'])\n",
    "    insurance = pd.DataFrame(data, columns=['保額', '保額區間', '保費', '保費區間', 'TWD'])\n",
    "    commodity = pd.DataFrame(data, columns=['商品分類_三標'])\n",
    "    age = pd.DataFrame(data, columns=['保險年齡'])\n",
    "    y = pd.DataFrame(data, columns=['是否已受理'])\n",
    "    \n",
    "    # commodity use embedding\n",
    "    type_dict = {'A&H':1, 'SP':2, 'RP1':3, 'RP2':4}\n",
    "    embeds = nn.Embedding(5, 4) # 5 means dict dim : 0-4\n",
    "    commodity = commodity.replace(type_dict)\n",
    "    commodity = torch.from_numpy(commodity.to_numpy())\n",
    "    commodity = torch.tensor(commodity)\n",
    "    commodity_embedded = embeds(commodity)\n",
    "    commodity = commodity_embedded.view(commodity_embedded.size(0),4).type(torch.DoubleTensor)\n",
    "    print('commodity: ',commodity.dtype)\n",
    "    \n",
    "#     # commodity use one-hot encoding\n",
    "#     commodity = pd.get_dummies(commodity)\n",
    "#     commodity = torch.from_numpy(commodity.to_numpy())\n",
    "    \n",
    "    # transfer other data to torch type\n",
    "    sales = torch.from_numpy(sales.to_numpy())\n",
    "    insurance = torch.from_numpy(insurance.to_numpy())\n",
    "    age = torch.from_numpy(age.to_numpy())\n",
    "    y = torch.from_numpy(y.to_numpy())\n",
    "    \n",
    "    \n",
    "    if datatype=='old':    #舊客戶\n",
    "        if wealth_loyalty:  # 使用客戶忠誠度、財富指標\n",
    "            level_dict = {'R1A':1, 'R1B':2, 'R1C':3, 'R2':4, 'R3':5, 'R4':6, 'R5':7}\n",
    "            customer = pd.DataFrame(data, columns=['客戶忠誠度', '財富指標'])\n",
    "            customer['客戶忠誠度'] = customer['客戶忠誠度'].str.get(1).astype(float)\n",
    "            customer['財富指標'] = customer['財富指標'].replace(level_dict)\n",
    "            customer = torch.from_numpy(customer.to_numpy())\n",
    "            x = torch.cat((sales, insurance, age, customer, commodity), 1)\n",
    "        else:\n",
    "            customerLevel = pd.DataFrame(data, columns=['客戶分群(NEW)'])\n",
    "            customerLevel = customerLevel['客戶分群(NEW)'].str.get(1).astype(float)\n",
    "            customerLevel = torch.from_numpy(customerLevel.to_numpy())\n",
    "            customerLevel = customerLevel.view(customerLevel.size(0), 1)\n",
    "            print('sales: ',sales.dtype)\n",
    "            print('insurance: ',insurance.dtype)\n",
    "            print('customerLevel: ',customerLevel.dtype)\n",
    "            x = torch.cat((sales, insurance, age, customerLevel, commodity), 1)\n",
    "    else:    #新客戶\n",
    "        x = torch.cat((sales, insurance, age, commodity), 1)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(csvpath, datatype, wealth_loyalty=False ,timesort=False):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        param csvpath : csv file path\n",
    "        param datatype : new/old customer\n",
    "        param wealth_loyalty : determine if put wealth and loyalty into datasets\n",
    "        param timesort : determine if sort the datetime when split data into train/test datasets\n",
    "        \n",
    "    Output:\n",
    "        x_train, y_train, x_test, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    # get dataframe\n",
    "    df = pd.read_csv(csvpath, encoding=\"utf-8\", index_col=[0])\n",
    "    \n",
    "    if datatype == 'new' or datatype=='all':\n",
    "        data = pd.DataFrame(df, columns=['保額', '保額區間', '保費', '保費區間', '商品分類_三標', '保險年齡', 'TWD', '是否已受理', '建議書_建立日'])\n",
    "    else:    # old              \n",
    "        if wealth_loyalty:    # 使用忠誠度和財富指標\n",
    "            data = pd.DataFrame(df, columns=['保額', '保額區間', '保費', '保費區間', '商品分類_三標', '保險年齡', 'TWD', '是否已受理', '財富指標', '客戶忠誠度', '建議書_建立日', 'R1A', 'R1B', 'R1C', 'R2', 'R3', 'R4', 'R5', 'L1', 'L2', 'L3', 'L4', 'L5', 'other']) \n",
    "        else:                 #使用客戶分群 \n",
    "            data = pd.DataFrame(df, columns=['保額', '保額區間', '保費', '保費區間', '商品分類_三標', '保險年齡', 'TWD', '是否已受理', '客戶分群(NEW)', '建議書_建立日','R1A', 'R1B', 'R1C', 'R2', 'R3', 'R4', 'R5', 'L1', 'L2', 'L3', 'L4', 'L5', 'other']) #只用客戶分群\n",
    "    \n",
    "    # Delete the row that has NaN\n",
    "    if datatype=='old':\n",
    "        data = data.dropna()\n",
    "    \n",
    "    # Data Augument\n",
    "    new_data = DataAugumenting(data)\n",
    "    \n",
    "    # sort datetime\n",
    "    if timesort:\n",
    "        # split data into train/test sets (split 8/2) with the sorting datetime\n",
    "        new_data = new_data.sort_values(by = '建議書_建立日').reset_index(drop=True)\n",
    "        train_data = new_data[0:int(len(new_data)*0.8)]\n",
    "        test_data = new_data[int(len(new_data)*0.8):]\n",
    "    else:\n",
    "        # split data into train/test sets (random with 8/2)\n",
    "        msk = np.random.rand(len(new_data)) < 0.8\n",
    "        train_data = new_data[msk]\n",
    "        test_data = new_data[~msk]\n",
    "    \n",
    "    # Data preprocessing\n",
    "    x_train, y_train = DataPreprocessing(train_data, datatype, wealth_loyalty)\n",
    "    x_test, y_test = DataPreprocessing(test_data, datatype, wealth_loyalty)\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdataloader(x, y, batch_size):\n",
    "    \"\"\"\n",
    "    Goal : change torch to dataset\n",
    "    \n",
    "    \"\"\"\n",
    "    # change torch to dataset\n",
    "    dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "    dataloader = Data.DataLoader(\n",
    "        dataset = dataset,\n",
    "        batch_size = batch_size,\n",
    "        drop_last=True, \n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(preds)\n",
    "    acc = (rounded_preds == y).float()\n",
    "    acc = acc.sum() / len(y)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class MyDNN(nn.Module):\n",
    "    def __init__(self, model_args):\n",
    "        super(MyDNN, self).__init__()\n",
    "        self.args = model_args\n",
    "        \n",
    "        # init args\n",
    "        self.input_dim = self.args.input_dim\n",
    "        self.hidden_dim = self.args.hidden_dim\n",
    "        self.output_dim = self.args.output_dim\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Linear(self.hidden_dim, self.output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_dim)\n",
    "        output = self.layers(x.float())\n",
    "        return output\n",
    "    \n",
    "    def printModel(self):\n",
    "        print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mymodel(object):\n",
    "    \"\"\"\n",
    "    Methods:\n",
    "        - fit()        : Train the model \n",
    "        - predict()    : Output the prediction\n",
    "        - evaluate()   : Calculate scores\n",
    "        - save_model() : Save the model (.h5)\n",
    "        \n",
    "    Parameters:\n",
    "        - epochs: int,\n",
    "            Numer of iterations to run all data\n",
    "            \n",
    "        - batch_size: int,\n",
    "            Minibatch size\n",
    "            \n",
    "        - learning rate: float,\n",
    "            Initial learning rate\n",
    "            \n",
    "        - use_cuda: boolean,\n",
    "            Run the model on gpu or cpu\n",
    "            \n",
    "        - optimizer: Algo of optimizer\n",
    "        \n",
    "        - criterion : Loss function\n",
    "        \n",
    "        - model_name: Model name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(self,\n",
    "                 epochs=None, \n",
    "                 batch_size=None, \n",
    "                 learning_rate=None,\n",
    "                 use_cuda=False, \n",
    "                 model_name=\"unknown_model.h5\", \n",
    "                 model_args=None):\n",
    "        \n",
    "        # model related\n",
    "        self._net = None\n",
    "        self.model_args = model_args\n",
    "        \n",
    "        # learning related\n",
    "        self._batch_size = batch_size\n",
    "        self._epochs = epochs\n",
    "        self._learning_rate = learning_rate\n",
    "        self._device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "        self._net = MyDNN(self.model_args).to(self._device)\n",
    "        self._optimizer = optim.SGD(self._net.parameters(), lr = self._learning_rate, momentum=0.9)\n",
    "        self._criterion = nn.BCELoss()\n",
    "        self._model_name = model_name\n",
    "            \n",
    "    def fit(self, trainloader):\n",
    "        self._net.train()\n",
    "        print(self._net)\n",
    "        \n",
    "        for epoch in range(self._epochs):\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            epoch_acc = 0\n",
    "            for step, (batch_x, batch_y) in enumerate(trainLoader):\n",
    "            \n",
    "                batch_x = batch_x.to(self._device)\n",
    "                batch_y = batch_y.to(self._device)\n",
    "\n",
    "                preds = self._net(batch_x.long())\n",
    "                losses = self._criterion(preds, batch_y.float())\n",
    "                acc = binary_accuracy(preds, batch_y)\n",
    "                \n",
    "                # Back prop.\n",
    "                self._optimizer.zero_grad()\n",
    "                losses.backward()\n",
    "                self._optimizer.step()\n",
    "\n",
    "                epoch_loss += losses.item()\n",
    "                epoch_acc += acc\n",
    "            print('epoch:{} | loss:{:4f} | acc:{:4f}'.format(epoch+1, epoch_loss/len(trainLoader), epoch_acc/len(trainLoader)))\n",
    "            \n",
    "    def predict(self, x_test):\n",
    "        x_test = x_test.to(self._device)\n",
    "        return self._net(x_test)\n",
    "    \n",
    "    def evaluate(self, x_test, y_test):\n",
    "        x_test = x_test.to(self._device)\n",
    "        \n",
    "        self._net.eval()\n",
    "        y_preds = self._net(x_test)\n",
    "        y_preds = y_preds.cpu()\n",
    "        y_preds = torch.round(y_preds)\n",
    "        \n",
    "        # 求 f1-score\n",
    "        TP=0; FN=0; FP=0; TN=0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i]-y_preds[i]==1:\n",
    "                FN += 1\n",
    "            elif y_test[i]-y_preds[i]==-1:\n",
    "                FP += 1\n",
    "            else:\n",
    "                if y_test[i]==1: TP += 1\n",
    "                else: TN += 1\n",
    "\n",
    "        print([[TP, FN], [FP, TN]])\n",
    "\n",
    "        accuracy = (TP+TN)/len(y_test)\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f1_score = 2/((1/precision)+1/recall)\n",
    "\n",
    "        print('len:',len(y_test))\n",
    "        print('acc : ', accuracy)\n",
    "        print('recall: ', recall)\n",
    "        print('precision: ', precision)\n",
    "        print('f1 score : ', f1_score)\n",
    "    \n",
    "    def save_model(self):\n",
    "        torch.save(self._net, './model/' + self._model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "        input_dim:\n",
    "            -新客戶: 10\n",
    "            -舊客戶: \n",
    "                - 使用客戶分群: 24\n",
    "                - 使用財富和忠誠度: 25\n",
    "    \"\"\"\n",
    "    \n",
    "    model_parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # model dependent arguments\n",
    "    model_parser = argparse.ArgumentParser()\n",
    "    model_parser.add_argument('--input_dim', type=int, default=10)\n",
    "    model_parser.add_argument('--hidden_dim', type=int, default=32)\n",
    "    model_parser.add_argument('--output_dim', type=int, default=1)\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    # data/train arguments\n",
    "    parser.add_argument('--epochs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=32)\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001)\n",
    "    parser.add_argument('--use_cuda', type=bool, default=True)\n",
    "    \n",
    "    config = parser.parse_args(args=[])\n",
    "    model_config = model_parser.parse_args(args=[])\n",
    "    \n",
    "        \n",
    "    # data parameters\n",
    "    csvpath = \"./data/preprocessing_new.csv\"\n",
    "    datatype = 'new'\n",
    "    timesort = False\n",
    "    wealth_loyalty = False\n",
    "    \n",
    "    model_name = \"test.h5\"\n",
    "    \n",
    "    \n",
    "\n",
    "    # load data\n",
    "    x_train, y_train, x_test, y_test = getData(csvpath, datatype, wealth_loyalty, timesort)\n",
    "    trainLoader = getdataloader(x_train, y_train, config.batch_size)\n",
    "    \n",
    "    print('x_train: ',x_train.shape)\n",
    "    print('x_test: ',x_test.shape)\n",
    "    \n",
    "    model = Mymodel(epochs=config.epochs,\n",
    "                    batch_size=config.batch_size,\n",
    "                    learning_rate=config.learning_rate,\n",
    "                    use_cuda=config.use_cuda, \n",
    "                    model_name=model_name, \n",
    "                    model_args=model_config)\n",
    "    \n",
    "    # fit model\n",
    "    model.fit(trainLoader)\n",
    "    \n",
    "    # evaluate model\n",
    "    model.evaluate(x_test, y_test)\n",
    "    model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TP=12061; FN=12469; FP=12774; TN=18339\n",
    "# accuracy = (TP+TN)/len(y_test)\n",
    "# precision = TP/(TP+FP)\n",
    "# recall = TP/(TP+FN)\n",
    "# f1_score = 2/((1/precision)+1/recall)\n",
    "\n",
    "# print('len:',len(y_test))\n",
    "# print('acc : ', accuracy)\n",
    "# print('recall: ', recall)\n",
    "# print('precision: ', precision)\n",
    "# print('f1 score : ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
